{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5e56a9-1a46-4377-8bb5-6fbdce8b9686",
   "metadata": {},
   "source": [
    "# MLOps in BQML - e-commerce scenario\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a>\n",
    "       <img src=\"https://vitalflux.com/wp-content/uploads/2021/09/google-cloud-bigquery-ml.png\" style=\"max-width: 75%; height: auto;\">\n",
    "    </a>\n",
    "  </td> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f1b502-b4b1-46c3-bc84-669aa579de7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "The purpose of this lab is to go through capabilities of BigQuery ML when modelling and maintaining a machine learning model based on tabular data. Throughout this lab, you will learn how to read historical e-commerce data stored in data warehouse, perform exploratory data analysis (EDA), do feature engineering, train a model using feature store, register your model in a model registry, evaluate your model, deploy your model to an endpoint, do inference on your model with feature store, and monitor your model.\n",
    "\n",
    "This lab uses the following Google Cloud services and resources:\n",
    "\n",
    "- [Vertex AI](https://cloud.google.com/vertex-ai/)\n",
    "- [BigQuery](https://cloud.google.com/bigquery/)\n",
    "- [Google Cloud Storage](https://cloud.google.com/storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9317dcd5-3c2e-4045-be6a-5369d73de4cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import packages\n",
    "\n",
    "Import the following packages required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a516d-6190-4e27-8419-9b4a2d8a7fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade google-api-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3595616-3cd3-4218-a46e-0c205f6b8f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade pandas-gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68833932-0205-41fd-85d1-6a33527e8e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "import random\n",
    "import numpy as np\n",
    "import google.cloud.aiplatform as aip\n",
    "\n",
    "from pandas import read_gbq\n",
    "from google.cloud import bigquery\n",
    "from typing import Union\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud.aiplatform import gapic as aip_gapic\n",
    "from google.cloud.aiplatform import model_monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65c556e-7709-4988-b5ad-ee8f6a082855",
   "metadata": {},
   "source": [
    "### Setup your environment\n",
    "\n",
    "Run the next cell to set your project ID and some of the other constants used in the lab.\n",
    "\n",
    "#### >>> PLEASE MODIFY FOLLOWING VARIABLES <<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6f86f5-88fd-43c5-a112-008ee9932ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# THESE\n",
    "PROJECT_ID = \"dprzek-vertex\"\n",
    "DATASET_NAME = \"workshop_ecommerce\"\n",
    "TABLE_NAME = \"trans_sample\"\n",
    "MODEL_NAME = \"ecommerce_workshop_model\"\n",
    "ENDPOINT_NAME = \"endpoint_ecommerce_workshop\"\n",
    "MONITORING_JOB_NAME = \"ecommerce_monit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7a0b00-39b7-4bbc-b6c8-b36877537ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT THESE\n",
    "TARGET = \"purchase\"\n",
    "\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_NAME = 'ecommerce_workshop_bucket'\n",
    "\n",
    "# create a Cloud Storage bucket\n",
    "!gsutil mb -l {REGION} gs://{BUCKET_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb6359a-e8d4-4439-b829-49b8e07a9ccf",
   "metadata": {},
   "source": [
    "#### Create helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9291ba4b-243b-4688-ac47-0561d9f148c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wrapper to use BigQuery client to run query/job, return job ID or result as DF\n",
    "def run_bq_query(sql: str, show=False) -> Union[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Run a BigQuery query and return the job ID or result as a DataFrame\n",
    "    Args:\n",
    "        sql: SQL query, as a string, to execute in BigQuery\n",
    "        show: A flag to show query result in a Pandas Dataframe\n",
    "    Returns:\n",
    "        df: DataFrame of results from query,  or error, if any\n",
    "    \"\"\"\n",
    "\n",
    "    bq_client = bigquery.Client()\n",
    "\n",
    "    # Try dry run before executing query to catch any errors\n",
    "    job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "    bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    # If dry run succeeds without errors, proceed to run query\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    client_result = bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    job_id = client_result.job_id\n",
    "\n",
    "    # Wait for query/job to finish running. then get & return data frame\n",
    "    result = client_result.result()\n",
    "    print(f\"Finished job_id: {job_id}\")\n",
    "    \n",
    "    if show:\n",
    "        df = result.to_arrow().to_pandas()\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4225d4-9a8c-4101-82f9-1387d13b5138",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Transactions data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f7ee2f-8c67-4d71-bae0-4337bdfdee4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_bq_query(\n",
    "    f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET_NAME}.{TABLE_NAME}` as\n",
    "    SELECT\n",
    "      sessions.fullVisitorId,\n",
    "      sessions.ga_session_id,\n",
    "      sessions.churned,\n",
    "      sessions.event_date,\n",
    "      sessions.isMobile,\n",
    "      sessions.operatingSystem,\n",
    "      sessions.browser,\n",
    "      sessions.country,\n",
    "      sessions.city,\n",
    "      sessions.firstSource,\n",
    "      sessions.firstMedium,\n",
    "      sessions.sessionNumber,\n",
    "      sessions.latest_ecommerce_progress,\n",
    "      sessions.isFirstVisit,\n",
    "      sessions.productPagesViewed,\n",
    "      sessions.addedToCart,\n",
    "      sessions.purchase,\n",
    "\n",
    "      users.totalHits,\n",
    "      users.totalPageviews,\n",
    "\n",
    "      visits.totalVisits,\n",
    "\n",
    "      engagement.totalTimeOnSite, # bucket\n",
    "      engagement.engagement_seconds,\n",
    "      engagement.engagement_minutes,\n",
    "      engagement.engagement_avg_seconds,\n",
    "      engagement.engagement_avg_minutes,\n",
    "\n",
    "      source.source,\n",
    "      source.medium,\n",
    "      source.campaign,\n",
    "\n",
    "    FROM (\n",
    "          SELECT\n",
    "            fullVisitorId,\n",
    "            session_id,\n",
    "            ga_session_id,\n",
    "            churned,\n",
    "            event_date,\n",
    "            isMobile,\n",
    "            operatingSystem,\n",
    "            browser,\n",
    "            country,\n",
    "            city,\n",
    "            firstSource,\n",
    "            firstMedium,\n",
    "            MAX(ga_session_number) sessionNumber,\n",
    "            MAX(latest_ecommerce_progress) latest_ecommerce_progress,\n",
    "            MAX(isFirstVisit) isFirstVisit,\n",
    "            MAX(productPagesViewed) productPagesViewed,\n",
    "            MAX(addedToCart) addedToCart,\n",
    "            MAX(purchase) purchase\n",
    "          FROM (\n",
    "                SELECT\n",
    "                  user_pseudo_id fullVisitorId,\n",
    "                  CONCAT(user_pseudo_id, \"-\", (SELECT value.int_value FROM unnest(event_params) WHERE key=\"ga_session_id\")) session_id,\n",
    "                  (select value.int_value from unnest(event_params) where key = 'ga_session_id') ga_session_id,\n",
    "                  (select value.int_value from unnest(event_params) where key = 'ga_session_number') ga_session_number,\n",
    "                  IF (TIMESTAMP_MICROS(event_timestamp) < TIMESTAMP_ADD(TIMESTAMP_MICROS(user_first_touch_timestamp), INTERVAL 24 HOUR), 1, 0 ) churned,\n",
    "                  event_date,\n",
    "                  CASE device.category WHEN 'mobile' THEN 0  ELSE 1 END AS isMobile,\n",
    "                  device.operating_system operatingSystem,\n",
    "                  device.web_info.browser browser,\n",
    "                  geo.country AS country,\n",
    "                  IFNULL(geo.city, '') city,\n",
    "                  traffic_source.source firstSource,\n",
    "                  traffic_source.medium firstMedium,\n",
    "                  CASE event_name WHEN 'first_visit' THEN 1  ELSE 0 END isFirstVisit,\n",
    "                  CASE event_name WHEN 'view_item' THEN 1 ELSE 0 END productPagesViewed,\n",
    "                  CASE event_name WHEN 'add_to_cart' THEN 1  ELSE 0 END addedToCart,\n",
    "                  CASE event_name WHEN 'purchase' THEN 1  ELSE 0 END purchase,\n",
    "                  CASE\n",
    "                    WHEN event_name = 'view_item' THEN 1\n",
    "                    WHEN event_name = 'add_to_cart' THEN 2\n",
    "                    WHEN event_name = 'view_cart' THEN 3\n",
    "                    WHEN event_name = 'begin_checkout' THEN 4\n",
    "                    WHEN event_name = 'purchase' THEN 5\n",
    "                  ELSE 0 END AS latest_ecommerce_progress\n",
    "\n",
    "              FROM\n",
    "                `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n",
    "              WHERE\n",
    "                platform = \"WEB\"\n",
    "                and (select value.int_value from unnest(event_params) where key = 'ga_session_id') IS NOT NULL\n",
    "                -- and user_pseudo_id = '335679038.1695746809'\n",
    "              GROUP BY 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18)\n",
    "\n",
    "              GROUP BY 1,2,3,4,5,6,7,8,9,10,11,12\n",
    "            ) sessions\n",
    "\n",
    "    LEFT JOIN (\n",
    "\n",
    "        SELECT\n",
    "        user_pseudo_id fullVisitorId,\n",
    "        CONCAT(user_pseudo_id, \"-\", (SELECT value.int_value FROM unnest(event_params) WHERE key=\"ga_session_id\")) session_id,\n",
    "        COUNT(user_pseudo_id) totalHits,\n",
    "        COUNTIF(event_name = 'page_view') totalPageviews\n",
    "        FROM\n",
    "          `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n",
    "        WHERE\n",
    "          platform = \"WEB\"\n",
    "          -- and user_pseudo_id = '335679038.1695746809'\n",
    "        GROUP BY 1,2\n",
    "    ) users USING(session_id)\n",
    "\n",
    "    LEFT JOIN (\n",
    "\n",
    "        SELECT\n",
    "        user_pseudo_id AS fullVisitorId,\n",
    "        CONCAT(user_pseudo_id, \"-\", (SELECT value.int_value FROM unnest(event_params) WHERE key=\"ga_session_id\")) session_id,\n",
    "        COUNT(DISTINCT (select value.int_value from unnest(event_params) where key = 'ga_session_id')) totalVisits\n",
    "        FROM\n",
    "          `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n",
    "        WHERE\n",
    "        platform = \"WEB\"\n",
    "        -- and user_pseudo_id = '335679038.1695746809'\n",
    "        GROUP BY 1,2\n",
    "    ) visits USING(session_id)\n",
    "\n",
    "    LEFT JOIN (\n",
    "\n",
    "        SELECT\n",
    "        user_pseudo_id fullVisitorId,\n",
    "        session_id,\n",
    "        MAX(engagement_time_msec) totalTimeOnSite,\n",
    "        cast(coalesce(sum(engagement_time_seconds),0) as INT64) engagement_seconds,\n",
    "        cast(coalesce(sum(engagement_time_minutes),0) as INT64) engagement_minutes,\n",
    "        cast(coalesce(avg(engagement_time_seconds),0) as INT64) engagement_avg_seconds,\n",
    "        cast(coalesce(avg(engagement_time_minutes),0) as INT64) engagement_avg_minutes\n",
    "        FROM (\n",
    "              SELECT\n",
    "              user_pseudo_id,\n",
    "              CONCAT(user_pseudo_id, \"-\", (SELECT value.int_value FROM unnest(event_params) WHERE key=\"ga_session_id\")) session_id,\n",
    "              (select value.int_value from unnest(event_params) where key = 'engagement_time_msec') engagement_time_msec,\n",
    "              max((select value.string_value from unnest(event_params) where key = 'session_engaged')) as session_engaged,\n",
    "              sum((select value.int_value from unnest(event_params) where key = 'engagement_time_msec'))/1000 as engagement_time_seconds,\n",
    "              sum((select value.int_value from unnest(event_params) where key = 'engagement_time_msec'))/(1000 * 60) as engagement_time_minutes\n",
    "              FROM\n",
    "              `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n",
    "              WHERE\n",
    "              platform = \"WEB\"\n",
    "              -- and user_pseudo_id = '335679038.1695746809'\n",
    "              group by 1,2,3\n",
    "        )\n",
    "        GROUP BY 1,2\n",
    "    ) engagement USING(session_id)\n",
    "\n",
    "    LEFT JOIN (\n",
    "\n",
    "        SELECT\n",
    "        user_pseudo_id AS fullVisitorId,\n",
    "        CONCAT(user_pseudo_id, \"-\", (SELECT value.int_value FROM unnest(event_params) WHERE key=\"ga_session_id\")) session_id,\n",
    "        (array_agg((select value.string_value from unnest(event_params) where key = 'source') ignore nulls order by event_timestamp)[offset(0)]) as source,\n",
    "        (array_agg((select value.string_value from unnest(event_params) where key = 'medium') ignore nulls order by event_timestamp)[offset(0)]) as medium ,\n",
    "        (array_agg((select value.string_value from unnest(event_params) where key = 'campaign') ignore nulls order by event_timestamp)[offset(0)]) as campaign\n",
    "        FROM\n",
    "          `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n",
    "        WHERE\n",
    "        platform = \"WEB\"\n",
    "        -- and user_pseudo_id = '335679038.1695746809'\n",
    "        GROUP BY 1,2\n",
    "    ) source USING(session_id)\n",
    "    \"\"\", show=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7dcded-eb09-4d5d-8c36-ec530cc99d4f",
   "metadata": {},
   "source": [
    "### Exploratory data analysis of transaction data in BigQuery\n",
    "\n",
    "In this section, you'll explore the data by running queries and creating a couple of plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d728f60d-5f5d-40f0-a532-ed952d3849f9",
   "metadata": {},
   "source": [
    "#### Let’s add some calculated metrics:\n",
    "\n",
    "1. Average Price = Total Revenue / Total Quantity Sold\n",
    "2. Average Quantity Per Order = Average Quantity Per Order = Total Quantity Sold / Number of Orders\n",
    "3. Cart Conversion Rate = (Number of Orders / Add to Carts) * 100\n",
    "4. Cart Abandonment Rate = (Add to Carts — Number of Orders) / Add to Carts) * 100\n",
    "\n",
    "The following query will add columns and do the calculations for the desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ae88f-9134-4ec4-bd74-9793372edfcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_bq_query(\n",
    "    \"\"\"\n",
    "    DECLARE date1, date2 STRING;\n",
    "    SET (date1, date2) = ('20000101','20240630');\n",
    "\n",
    "    -- CTE for sales data excluding items with \"(not set)\" in item_id or item_name\n",
    "    WITH sales AS (\n",
    "      SELECT\n",
    "        items.item_id AS item_id,\n",
    "        SUM(items.quantity) AS total_quantity,\n",
    "        COUNT(DISTINCT event_timestamp) AS orders,\n",
    "        SUM(items.item_revenue) AS total_revenue\n",
    "      FROM `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`,\n",
    "      UNNEST(items) AS items\n",
    "      WHERE _TABLE_SUFFIX BETWEEN date1 AND date2\n",
    "        AND event_name = 'purchase'\n",
    "        AND items.item_id IS NOT NULL\n",
    "        AND items.item_name IS NOT NULL\n",
    "        AND items.item_id != '(not set)'\n",
    "        AND items.item_name != '(not set)'\n",
    "      GROUP BY item_id\n",
    "    ),\n",
    "\n",
    "    -- CTE for add-to-carts data excluding items with \"(not set)\" in item_id or item_name\n",
    "    add_to_carts AS (\n",
    "      SELECT\n",
    "        items.item_id AS item_id,\n",
    "        items.item_name AS item_name,\n",
    "        COUNT(DISTINCT event_timestamp) AS add_to_carts\n",
    "      FROM `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`,\n",
    "      UNNEST(items) AS items\n",
    "      WHERE _TABLE_SUFFIX BETWEEN date1 AND date2\n",
    "        AND event_name = 'add_to_cart'\n",
    "        AND items.item_id IS NOT NULL\n",
    "        AND items.item_name IS NOT NULL\n",
    "        AND items.item_id != '(not set)'\n",
    "        AND items.item_name != '(not set)'\n",
    "      GROUP BY item_id, item_name\n",
    "    )\n",
    "\n",
    "    -- Final SELECT to combine sales and add-to-carts data\n",
    "    SELECT\n",
    "      c.item_id AS item_id,\n",
    "      c.item_name AS item_name,\n",
    "      c.add_to_carts AS add_to_carts,\n",
    "      IFNULL(s.orders, 0) AS orders,\n",
    "      IFNULL(s.total_quantity, 0) AS total_quantity_ordered,\n",
    "      IFNULL(s.total_revenue, 0.0) AS revenue,\n",
    "      -- Calculate average price (revenue divided by quantity)\n",
    "      IFNULL(s.total_revenue / NULLIF(s.total_quantity, 0), 0.0) AS avg_price,\n",
    "      -- Calculate average quantity per order\n",
    "      IFNULL(s.total_quantity / NULLIF(s.orders, 0), 0.0) AS avg_quantity_per_order,\n",
    "      -- Calculate cart conversion rate (orders divided by add to carts)\n",
    "      IFNULL(s.orders / NULLIF(c.add_to_carts, 0), 0.0) AS cart_conversion_rate,\n",
    "      -- Calculate cart abandonment rate ensuring it is not negative\n",
    "      GREATEST(1 - IFNULL(s.orders / NULLIF(c.add_to_carts, 0), 0.0), 0) AS cart_abandonment_rate\n",
    "    FROM add_to_carts AS c\n",
    "    LEFT JOIN sales AS s ON c.item_id = s.item_id\n",
    "    ORDER BY orders DESC;\n",
    "    \"\"\", show=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b720b6-e0c1-4ed2-bf24-33f50c19fa79",
   "metadata": {},
   "source": [
    "#### < space for further EDA >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4ce460-8350-44e4-89b9-671699f7c4d3",
   "metadata": {},
   "source": [
    "### Creating logistic regression model in BigQuery\n",
    "\n",
    "The procedure can (or even should!) be augmented with feature engineering steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0b147e-f389-4229-ac62-0364ec6edc3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_bq_query(\n",
    "    f\"\"\"\n",
    "    CREATE OR REPLACE MODEL\n",
    "      `{PROJECT_ID}.{DATASET_NAME}.{MODEL_NAME}`\n",
    "\n",
    "    OPTIONS(MODEL_TYPE = 'LOGISTIC_REG',\n",
    "        INPUT_LABEL_COLS = ['purchase'],\n",
    "        enable_global_explain=TRUE,\n",
    "        model_registry='vertex_ai'\n",
    "        )\n",
    "        AS\n",
    "\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      `{PROJECT_ID}.{DATASET_NAME}.{TABLE_NAME}`\n",
    "    WHERE \n",
    "      MOD(ABS(FARM_FINGERPRINT(CAST(event_date AS STRING))),1000) > 900\n",
    "    \"\"\", show=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c3b63-9642-4933-a852-4e8da6d61630",
   "metadata": {},
   "source": [
    "##### A brief look at feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2d1ab9-71c3-4766-a233-be0606f98fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_bq_query(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      ML.GLOBAL_EXPLAIN(MODEL `{PROJECT_ID}.{DATASET_NAME}.{MODEL_NAME}`)\n",
    "    \"\"\", show=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52df6b2-593a-443b-85b9-370dd3eaca3b",
   "metadata": {},
   "source": [
    "#### Export model to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6a6620-bc14-4229-acb8-5004bce6212c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_bq_query(\n",
    "    f\"\"\"\n",
    "    EXPORT MODEL `{PROJECT_ID}.{DATASET_NAME}.{MODEL_NAME}` \n",
    "    OPTIONS(URI = 'gs://{BUCKET_NAME}/model')\n",
    "    \"\"\", show=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf8d17d-88f3-4eb5-91a1-f5362928202c",
   "metadata": {},
   "source": [
    "#### Register model in Vertex AI Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed390b3-6aeb-41a5-9422-4ac52d2f7434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Model Resource\n",
    "model = aip.Model.upload(\n",
    "    display_name=MODEL_NAME,\n",
    "    artifact_uri= f'gs://{BUCKET_NAME}/model',\n",
    "    serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-8:latest\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac34f34-e20c-4b44-bbe8-9dd2e9b3fe2c",
   "metadata": {},
   "source": [
    "#### Deploy model to Vertex AI endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88057567-1fae-4d53-bcf0-c509cec7322c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model = vertex_ai.Model(model_name=model.resource_name)\n",
    "\n",
    "endpoint = model.deploy(\n",
    "    deployed_model_display_name=ENDPOINT_NAME,\n",
    "    machine_type=\"n1-standard-4\",  # Or choose a suitable machine type\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82700cd6-00b8-49e3-9046-34366eceb60c",
   "metadata": {},
   "source": [
    "### Deploy model monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aad740-c088-485a-a927-e6c387d287ea",
   "metadata": {},
   "source": [
    "##### Put BigQuery table into Pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c06b82c-0fae-49f2-8eb8-9157ad062e0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "    SELECT * \n",
    "    FROM `{DATASET_NAME}.{TABLE_NAME}`\n",
    "\"\"\"\n",
    "\n",
    "# Read from BigQuery into Pandas DataFrame\n",
    "df = pd.read_gbq(query=query,project_id=PROJECT_ID)\n",
    "\n",
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7503669a-cc81-4cc2-b7b1-bc1d90bd3ad5",
   "metadata": {},
   "source": [
    "##### Take a brief look at data frame metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bead2d-ff73-47a5-882f-a26ab36fe123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0044c747-1471-48f9-9f13-ae119ddd5230",
   "metadata": {},
   "source": [
    "##### Convert all object columns to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5fb4dc-45e4-45c9-bf69-9445e41ae5b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[df.select_dtypes(['object']).columns] = df.select_dtypes(['object']).astype('string')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccf1cf5-9219-4bd8-bd0d-40b3c4571d8d",
   "metadata": {},
   "source": [
    "##### Drop target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f34997-49e4-4a30-9656-0659f582b0c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_nt = df.drop(TARGET, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f1dd4d-6b1c-4e54-aa2e-a5a2050f5bfa",
   "metadata": {},
   "source": [
    "##### Transform testing examples into list od dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdab309-840a-41a7-a39e-12135fc50fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract specific rows\n",
    "start_row = 17000\n",
    "end_row = 18000\n",
    "extracted_df = df_nt.iloc[start_row:end_row].copy()\n",
    "\n",
    "# Get column names and their data types\n",
    "column_dtypes = extracted_df.dtypes.to_dict()\n",
    "\n",
    "# Fill missing values in the extracted DataFrame (if any), handling StringArrays\n",
    "for col_name, col_dtype in column_dtypes.items():\n",
    "    if col_dtype == 'string':  # or isinstance(extracted_df[col_name].dtype, pd.StringDtype) \n",
    "        extracted_df[col_name] = extracted_df[col_name].fillna('')  # Fill with empty string\n",
    "    else:\n",
    "        extracted_df[col_name] = extracted_df[col_name].fillna(0)  # Fill numeric columns with 0\n",
    "\n",
    "# Get column names and their data types\n",
    "column_dtypes = extracted_df.dtypes.to_dict()\n",
    "\n",
    "# Create the list of dictionaries\n",
    "abc = []\n",
    "for _, row in extracted_df.iterrows():\n",
    "    row_dict = {}\n",
    "    for col_name, col_value in row.items():\n",
    "        # Convert data types based on column_dtypes\n",
    "        if column_dtypes[col_name] == 'Int64':\n",
    "            row_dict[col_name] = int(col_value) if pd.notnull(col_value) else 0 \n",
    "        elif column_dtypes[col_name] == 'Float64':\n",
    "            row_dict[col_name] = float(col_value) if pd.notnull(col_value) else 0.0 \n",
    "        else:\n",
    "            row_dict[col_name] = str(col_value) if pd.notnull(col_value) else \"\"\n",
    "\n",
    "    abc.append(row_dict)\n",
    "    \n",
    "#endpoint.predict(instances=abc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bf08bb-9e8e-4e35-b165-e5f2106ea781",
   "metadata": {},
   "source": [
    "## Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e947eb2-a782-433d-855a-6ae368d1b7fe",
   "metadata": {},
   "source": [
    "##### Define prerequisities to monitoring job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17947b2d-2dd8-4a81-b0dd-d26635b63f2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sampling rate (optional, default=.8)\n",
    "LOG_SAMPLE_RATE = 0.8  # @param {type:\"number\"}\n",
    "\n",
    "# Monitoring Interval in hours (optional, default=1).\n",
    "MONITOR_INTERVAL = 1  # @param {type:\"number\"}\n",
    "\n",
    "# Skew and drift thresholds.\n",
    "\n",
    "SKEW_THRESHOLDS = {\n",
    "    \"churned\": 0.003,\n",
    "    \"isMobile\": 0.003,\n",
    "    \"sessionNumber\": 0.003,\n",
    "    \"latest_ecommerce_progress\": 0.003, \n",
    "    \"isFirstVisit\": 0.003,\n",
    "    \"productPagesViewed\": 0.003,\n",
    "    \"addedToCart\": 0.003,\n",
    "    \"totalHits\": 0.003,\n",
    "    \"totalPageviews\": 0.003,\n",
    "    \"totalVisits\": 0.003,\n",
    "    \"totalTimeOnSite\": 0.003,\n",
    "    \"engagement_seconds\": 0.003,\n",
    "    \"engagement_minutes\": 0.003,\n",
    "    \"engagement_avg_seconds\": 0.003,\n",
    "    \"engagement_avg_minutes\": 0.003,\n",
    "}\n",
    "DRIFT_THRESHOLDS = {\n",
    "    \"churned\": 0.003,\n",
    "    \"isMobile\": 0.003,\n",
    "    \"sessionNumber\": 0.003,\n",
    "    \"latest_ecommerce_progress\": 0.003, \n",
    "    \"isFirstVisit\": 0.003,\n",
    "    \"productPagesViewed\": 0.003,\n",
    "    \"addedToCart\": 0.003,\n",
    "    \"totalHits\": 0.003,\n",
    "    \"totalPageviews\": 0.003,\n",
    "    \"totalVisits\": 0.003,\n",
    "    \"totalTimeOnSite\": 0.003,\n",
    "    \"engagement_seconds\": 0.003,\n",
    "    \"engagement_minutes\": 0.003,\n",
    "    \"engagement_avg_seconds\": 0.003,\n",
    "    \"engagement_avg_minutes\": 0.003,\n",
    "}\n",
    "ATTRIB_SKEW_THRESHOLDS = {\n",
    "    \"churned\": 0.003,\n",
    "    \"isMobile\": 0.003,\n",
    "    \"sessionNumber\": 0.003,\n",
    "    \"latest_ecommerce_progress\": 0.003, \n",
    "    \"isFirstVisit\": 0.003,\n",
    "    \"productPagesViewed\": 0.003,\n",
    "    \"addedToCart\": 0.003,\n",
    "    \"totalHits\": 0.003,\n",
    "    \"totalPageviews\": 0.003,\n",
    "    \"totalVisits\": 0.003,\n",
    "    \"totalTimeOnSite\": 0.003,\n",
    "    \"engagement_seconds\": 0.003,\n",
    "    \"engagement_minutes\": 0.003,\n",
    "    \"engagement_avg_seconds\": 0.003,\n",
    "    \"engagement_avg_minutes\": 0.003,\n",
    "}\n",
    "ATTRIB_DRIFT_THRESHOLDS = {\n",
    "    \"churned\": 0.003,\n",
    "    \"isMobile\": 0.003,\n",
    "    \"sessionNumber\": 0.003,\n",
    "    \"latest_ecommerce_progress\": 0.003, \n",
    "    \"isFirstVisit\": 0.003,\n",
    "    \"productPagesViewed\": 0.003,\n",
    "    \"addedToCart\": 0.003,\n",
    "    \"totalHits\": 0.003,\n",
    "    \"totalPageviews\": 0.003,\n",
    "    \"totalVisits\": 0.003,\n",
    "    \"totalTimeOnSite\": 0.003,\n",
    "    \"engagement_seconds\": 0.003,\n",
    "    \"engagement_minutes\": 0.003,\n",
    "    \"engagement_avg_seconds\": 0.003,\n",
    "    \"engagement_avg_minutes\": 0.003,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7670cb-24ef-49e2-beca-c0ef5c6bb70f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skew_config = model_monitoring.SkewDetectionConfig(\n",
    "    data_source=f\"bq://{PROJECT_ID}.{DATASET_NAME}.{TABLE_NAME}\",\n",
    "    skew_thresholds=SKEW_THRESHOLDS,\n",
    "    attribute_skew_thresholds=ATTRIB_SKEW_THRESHOLDS,\n",
    "    target_field=TARGET,\n",
    ")\n",
    "\n",
    "drift_config = model_monitoring.DriftDetectionConfig(\n",
    "    drift_thresholds=DRIFT_THRESHOLDS,\n",
    "    attribute_drift_thresholds=ATTRIB_DRIFT_THRESHOLDS,\n",
    ")\n",
    "\n",
    "objective_config = model_monitoring.ObjectiveConfig(\n",
    "    skew_config, drift_config\n",
    ")\n",
    "\n",
    "# Create sampling configuration\n",
    "random_sampling = model_monitoring.RandomSampleConfig(sample_rate=LOG_SAMPLE_RATE)\n",
    "\n",
    "# Create schedule configuration\n",
    "schedule_config = model_monitoring.ScheduleConfig(monitor_interval=MONITOR_INTERVAL)\n",
    "\n",
    "# Create alerting configuration.\n",
    "emails = [\"dprzek@google.com\"]\n",
    "alerting_config = model_monitoring.EmailAlertConfig(\n",
    "    user_emails=emails, enable_logging=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7118a695-809d-4cf4-897a-7a0705ddc4f1",
   "metadata": {},
   "source": [
    "#### Create monitoring job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7622a63-3368-4096-952a-76ba7a8d2931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_new = vertex_ai.ModelDeploymentMonitoringJob.create(\n",
    "    display_name=MONITORING_JOB_NAME,\n",
    "    logging_sampling_strategy=random_sampling,\n",
    "    schedule_config=schedule_config,\n",
    "    alert_config=alerting_config,\n",
    "    objective_configs=objective_config,\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    endpoint=endpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dd28b6-bc68-4aea-8c81-ee0a9827ac04",
   "metadata": {},
   "source": [
    "#### Request the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9811e-fff2-411c-af99-01df7055246e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint.predict(instances=abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c722a7-4a0a-4710-8e9a-2c1619f03e1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #close resources:\n",
    "\n",
    "# # [1] storage bucket\n",
    "# !gsutil -m rm -r gs://{BUCKET_NAME}/**\n",
    "# !gsutil rb gs://{BUCKET_NAME}\n",
    "\n",
    "# # [2] models and endpoints\n",
    "# def delete_all_models(PROJECT_ID, REGION):\n",
    "\n",
    "#     vertex_ai.init(project=PROJECT_ID, location=REGION)\n",
    "#     endpoints = vertex_ai.Endpoint.list()  # Get all endpoints\n",
    "\n",
    "#     for endpoint in endpoints:\n",
    "#         endpoint.undeploy_all()\n",
    "#         print(f\"Undeployed endpoints\")\n",
    "    \n",
    "#     for model in vertex_ai.Model.list():\n",
    "#         model.delete()\n",
    "#         print(f\"Deleted model: {model.name}\")\n",
    "\n",
    "# delete_all_models(PROJECT_ID, REGION)\n",
    "\n",
    "# # [3] experiments\n",
    "# experiments = vertex_ai.Experiment.list()\n",
    "# for experiment in experiments:\n",
    "#     experiment.delete(delete_backing_tensorboard_runs=True)\n",
    "\n",
    "# # [4] datasests\n",
    "# def delete_all_datasets():\n",
    "#     try:\n",
    "#         datasets = vertex_ai.TabularDataset.list() # or ImageDataset, TextDataset, etc.\n",
    "\n",
    "#         for dataset in datasets:\n",
    "#             dataset.delete()\n",
    "#             print(f\"Deleted dataset: {dataset.name}\")\n",
    "\n",
    "#         print(\"All datasets deleted successfully.\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error deleting datasets: {e}\")\n",
    "\n",
    "# delete_all_datasets()\n",
    "\n",
    "# # [5] featurestores\n",
    "# featurestores = vertex_ai.Featurestore.list() \n",
    "# for featurestore in featurestores:\n",
    "#     featurestore.delete(force=True)  # Delete with force to bypass checks\n",
    "\n",
    "# # [6] artifact registry\n",
    "# client = artifactregistry_v1.ArtifactRegistryClient()\n",
    "# repositories = client.list_repositories(parent=f\"projects/{PROJECT_ID}/locations/{REGION}\")\n",
    "# for repository in repositories:\n",
    "#     try:\n",
    "#         client.delete_repository(name=repository.name)\n",
    "#         print(f\"Deleted repository: {repository.name}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error deleting repository {repository.name}: {e}\")\n",
    "#     print(f\"Deleted featurestore: {featurestore.name}\")\n",
    "\n",
    "# # [7] metadata\n",
    "# # Initialize Metadata Service Client\n",
    "# metadata_client = MetadataServiceClient(client_options={\"api_endpoint\": f\"{REGION}-aiplatform.googleapis.com\"})\n",
    "\n",
    "# def delete_artifacts(metadata_store_id=\"default\"):  # Use 'default' for the default store\n",
    "#     parent = f\"projects/{PROJECT_ID}/locations/{REGION}/metadataStores/{metadata_store_id}\"\n",
    "#     artifacts = metadata_client.list_artifacts(parent=parent)\n",
    "\n",
    "#     for artifact in artifacts:\n",
    "#         metadata_client.delete_artifact(name=artifact.name)\n",
    "#         print(f\"Deleted artifact: {artifact.name}\")\n",
    "       \n",
    "# delete_artifacts()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
